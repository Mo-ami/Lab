
---
title: "Lab"
output:
  html_document:
    number_sections: true
  pdf_document: default
fontsize: 11pt
---

# Uppgift 1. Enkel linjär regression

## (a) Simulera data och anpassa modellen

Vi genererar heltal $x=1,\dots,20$ och simulerar
$y=\beta_0+\beta_1 x+\varepsilon$ med $\beta_0=2$, $\beta_1=1$, $\varepsilon\sim\mathcal{N}(0,\sigma^2)$, $\sigma=3$. Dessa värden ger $R^2$ mellan 70–90%.

```{r}
set.seed(123)                 # reproducerbart en gång 
x <- 1:20
beta0 <- 2
beta1 <- 1
sigma <- 3
eps <- rnorm(length(x), mean = 0, sd = sigma)
y <- beta0 + beta1*x + eps

fit <- lm(y ~ x)
summary(fit)
```


## (b) 95% konfidensintervall för $\beta_0,\beta_1$

```{r}
(ci <- confint(fit, level = 0.95))

```
Ja, de finns i intervallen. 

## (c) Grafisk diagnostik

Sexp figurer: spridningsdiagram (utan linje), spridningsdiagram med anpassad linje samt de 4 diagnostiska plottarna.

```{r}
op <- par(mfrow = c(2, 3), mar = c(4,4,2,1))
plot(x, y, main = "y mot x", xlab = "x", ylab = "y")
plot(x, y, main = "y mot x med anpassning", xlab = "x", ylab = "y")
abline(fit, lwd = 2)

plot(fit, which = 1)  # Residualer mot anpassade värden (Residuals vs Fitted)
plot(fit, which = 2)  # Normal Q-Q
plot(fit, which = 3)  # Scale-Location
plot(fit, which = 5)  # Residualer mot hävstång (Cook's konturer)
par(op)
```

**Vad plottarna visar:**

* **Spridningsdiagrammen**: linjärt samband tydligt.
* **Residualer mot anpassade värden**: kontrollerar linearitet & konstant varians (bör vara slumpmoln).
* **Normal Q–Q**: kontrollerar ungefärlig normalitet (punkter nära linjen).
* **Scale–Location**: kontrollerar homogen varians (platt band).
* **Residualer mot hävstång (Cook’s distans)**: flaggar hög hävstång/inflytande.

Modellen passar väl till datan. 


## (d) Upprepade simuleringar för att se diagnostikens variation

```{r}
seed <- sample(1:100, 1)
set.seed(seed)
# Simulera en ny datamängd vid varje körning och rita om diagnostiken
x <- 1:20
beta0 <- 2; beta1 <- 1; sigma <- 3
y <- beta0 + beta1*x + rnorm(length(x), 0, sigma)
fit <- lm(y ~ x)

op <- par(mfrow = c(2, 3), mar = c(4,4,2,1))
plot(x, y, main = "y mot x", xlab = "x", ylab = "y")
plot(x, y, main = "y mot x med anpassning", xlab = "x", ylab = "y"); abline(fit, lwd = 2)
plot(fit, which = 1); plot(fit, which = 2); plot(fit, which = 3); plot(fit, which = 5)
par(op)

set.seed(123)
```

Även när modellen stämmer kan residualmönster, QQ-svansar och Scale–Location-kurvan variera på grund av slump; plott av hävstång/Cook’s är oftast mest stabil såvida inte ett extremt drag uppstår. Små mönster ska tolkas med försiktighet.

## (e) Bryt mot antagandet om homogen varians (variansen ökar med $x$)

```{r}
set.seed(123)
x <- 1:20
beta0 <- 2; beta1 <- 1; sigma <- 0.8
y_het <- beta0 + beta1*x + rnorm(length(x), 0, sigma * (x/mean(x)))
fit_het <- lm(y_het ~ x)

op <- par(mfrow = c(2, 3), mar = c(4,4,2,1))
plot(x, y_het, main = "Heteroskedastisk y mot x")
plot(x, y_het, main = "Med anpassning"); abline(fit_het, lwd = 2)
plot(fit_het, which = 1); plot(fit_het, which = 2); plot(fit_het, which = 3); plot(fit_het, which = 5)
par(op)
```

**Tolkning (e):**

* Spridningsdiagrammen visar ett tydligt linjärt samband men **ökande spridning när x ökar**.
* **Residuals vs Fitted:** trattform – residualernas varians växer med anpassade värden ⇒ tydlig **heteroskedasticitet**.
* **Scale–Location:** stigande kurva bekräftar **icke-konstant varians**.
* **Q–Q:** punkter nära linjen ⇒ normalitetsantagandet verkar OK.
* **Residuals vs Leverage:** inga uppenbart inflytelserika observationer (Cook’s långt ifrån gränser).

## (f) Bryt mot linearitetsantagandet (sann kvadratisk term)

```{r}
set.seed(123)
x <- 1:20
beta0 <- 2; beta1 <- 0.2; beta2 <- 0.08; sigma <- 1.5
y_nl <- beta0 + beta1*x + beta2*x^2 + rnorm(length(x), 0, sigma)
fit_lin <- lm(y_nl ~ x)      # (fel)anpassa en linjär modell

op <- par(mfrow = c(2, 3), mar = c(4,4,2,1))
plot(x, y_nl, main = "Icke-linjär y mot x")
plot(x, y_nl, main = "Linjär anpassning över icke-linjär"); abline(fit_lin, lwd = 2)
plot(fit_lin, which = 1); plot(fit_lin, which = 2); plot(fit_lin, which = 3); plot(fit_lin, which = 5)
par(op)
```

**Tolkning (f):**

* Spridningsdiagrammen visar tydlig **krökning (kvadratisk trend)** – en linjär modell är fel 
* **Residuals vs Fitted:** markerad U-form ⇒ stark **icke-linearitet**.
* **Scale–Location:** ingen tydlig trattform ⇒ variansen verkar ungefär konstant.
* **Q–Q:** nära linjen ⇒ residualerna är ungefär **normala**.
* **Residuals vs Leverage:** ytterpunkter har hög **hävstång**, viss men inte extrem påverkan (Cook’s inte passerad).


## (g) Avvikare: inflytelserik vs icke-inflytelserik

Utgå från en ren linjär modell och stör en observation på två sätt.

```{r}
set.seed(123)
x <- 1:20
beta0 <- 2; beta1 <- 1; sigma <- 2
y_base <- beta0 + beta1*x + rnorm(length(x), 0, sigma)

## Fall 1: Icke-inflytelserik y-avvikare vid genomsnittlig hävstång
x1 <- x
y1 <- y_base
y1[10] <- y1[10] + 12     # stort residual vid måttligt x
fit1 <- lm(y1 ~ x1)

## Fall 2: Inflytelserik hög-hävstångs-avvikare (extremt x)
x2 <- x
x2[20] <- 40              # långt utanför designintervallet
y2 <- y_base
y2[20] <- beta0 + beta1*x2[20] + rnorm(1, 0, 6) + 10  # även förskjuten i y
fit2 <- lm(y2 ~ x2)

# Plottar: vardera i ett 2x3-upplägg
op <- par(mfrow = c(2, 3), mar = c(4,4,2,1))
plot(x1, y1, main = "Icke-inflytelserik avvikare")
plot(x1, y1, main = "Med anpassning"); abline(fit1, lwd = 2)
plot(fit1, which = 1); plot(fit1, which = 2); plot(fit1, which = 3); plot(fit1, which = 5)
par(op)

op <- par(mfrow = c(2, 3), mar = c(4,4,2,1))
plot(x2, y2, main = "Inflytelserik avvikare")
plot(x2, y2, main = "Med anpassning"); abline(fit2, lwd = 2)
plot(fit2, which = 1); plot(fit2, which = 2); plot(fit2, which = 3); plot(fit2, which = 5)
par(op)
```


**Tolkning (g):**

* **Icke-inflytelserik outlier (fall 1):** I spridningsdiagrammet syns en tydlig y-avvikare kring medel-x. Den ger **stort residual** (Residuals vs Fitted) och avviker i **Q–Q** men har **låg hävstång**; i **Residuals vs Leverage** ligger punkten långt till vänster och **under Cook’s**-konturer ⇒ liten påverkan på linjen.

* **Inflytelserik outlier (fall 2):** Punkt med **extremt x** drar regressionslinjen (synligt i “Med anpassning”). I **Residuals vs Leverage** har den **hög hävstång** och ligger nära/över **Cook’s**-konturer ⇒ **inflytelserik**. Residualen är inte nödvändigtvis störst i “Residuals vs Fitted”, men kombinationen av stort leverage + Cook’s gör den tydligt påverkande.

---

# Uppgift 2. Multipel linjär regression — Cigarettdata

## (a) Enkla regressioner för prediktion av CO

```{r}
# Läs in data -------------------------------------------------------------
cig <- read.csv("cigarette.csv", stringsAsFactors = FALSE)

# Snabb översikt
str(cig)

# Spridningsdiagram med enkla linjära anpassningar
op <- par(mfrow = c(1, 3), mar = c(4,4,2,1))
plot(cig$tar, cig$CO, xlab = "Tjära (mg)", ylab = "CO (mg)", main = "CO ~ tar")
abline(lm(CO ~ tar, data = cig), lwd = 2)
plot(cig$nico, cig$CO, xlab = "Nikotin (mg)", ylab = "CO (mg)", main = "CO ~ nico")
abline(lm(CO ~ nico, data = cig), lwd = 2)
plot(cig$weight, cig$CO, xlab = "Vikt (g)", ylab = "CO (mg)", main = "CO ~ weight")
abline(lm(CO ~ weight, data = cig), lwd = 2)
par(op)

# Anpassa enkla modeller och summera
m_tar    <- lm(CO ~ tar,    data = cig)
m_nico   <- lm(CO ~ nico,   data = cig)
m_weight <- lm(CO ~ weight, data = cig)

summary(m_tar)
summary(m_nico)
summary(m_weight)
```

**Tolkning 2(a):**

* **CO \~ tar:** Mycket starkt linjärt samband. $R^2 \approx 0.92$, lutning ≈ **0.81 mg CO per mg tjära** (p ≪ 0.001). Bra för prediktion.
* **CO \~ nico:** Också starkt linjärt samband. $R^2 \approx 0.86$, lutning ≈ **12.4 mg CO per mg nikotin** (p ≪ 0.001). Bra för prediktion.
* **CO \~ weight:** Svagt samband. $R^2 \approx 0.22$, lutning signifikant men osäker praktiskt (p≈0.02); spridningen stor ⇒ **svag prediktor**.

Enkel linjär regression fungerar **väl** för att prediktera CO med **tjära** eller **nikotin** var för sig, men **dåligt** med **vikt** som ensam förklarande variabel.

## (b) Multipel regression med alla tre prediktorer

```{r}
m_all <- lm(CO ~ tar + nico + weight, data = cig)
summary(m_all)
```

**Tolkning 2(b):**

* I den multipla modellen är **tjära** positiv och **signifikant** (β≈0.96, p≈7e-4).
* **Nikotin** blir **icke-signifikant** och byter tecken (β≈−2.6, p≈0.51) – typiskt tecken på **kollinearitet** med tjära.
* **Vikt** är också **icke-signifikant** (p≈0.97).
* $R^2=0.919$ är bara marginellt högre än för CO\~tar, men **justerat $R^2=0.907$ är lägre** än för CO\~tar (≈0.913), och residual-SE är större (1.45 vs 1.40).

Att lägga till nikotin och vikt ger ingen praktisk förbättring; **CO\~tar** räcker bäst av de provade modellerna.


## (c) Parvisa plottar för att förklara (b)

```{r}
pairs(~ CO + tar + nico + weight, data = cig)
```

**Tolkning 2(c):**

* **CO–tar** och **CO–nico**: tydliga, starkt positiva linjära samband → båda förklarar CO bra var för sig.
* **CO–weight**: svagt samband och stor spridning → dålig ensam prediktor.
* **tar–nico**: mycket starkt positiv korrelation → **kollinearitet**. Det förklarar att nikotin blir icke-signifikant och kan byta tecken i den multipla modellen i (b) när tjära redan finns med.
* **weight** mot tar/nico: inga starka samband → liten extra information att tillföra modellen.

## (d) Residualdiagnostik för den multipla regressionen

```{r}
op <- par(mfrow = c(2, 2))
plot(m_all)
par(op)
```

**Tolkning 2(d):**

* **Residuals vs Fitted:** svag krökning och systematik; inte helt linjärt.
* **Q–Q:** nära linjen men några svansavvikelser (t.ex. 17, 25) ⇒ något tunga svansar.
* **Scale–Location:** ökande trend → tecken på **heteroskedasticitet** (större spridning vid höga förklarade värden).
* **Residuals vs Leverage:** observation **30** har **hög hävstång** och **stort residual** (nära/över Cook’s) ⇒ **inflytelserik**.

Den multipla linjära modellen är delvis rimlig men diagnosen visar möjlig icke-linearitet, icke-konstant varians och en inflytelserik punkt (nr 30) som bör utredas/hanteras.

## (e) Identifiera och uteslut den tvivelaktiga observationen, anpassa om

```{r}
# Influensdiagnostik
infl <- influence.measures(m_all)
cook <- cooks.distance(m_all)
lev  <- hatvalues(m_all)

n <- nrow(cig)
thr <- 4/n                           
flag <- which(cook > thr)
data.frame(brand = cig$brand[flag], cooksD = cook[flag], leverage = lev[flag])

# Ta bort den mest tvivelaktiga och anpassa om
idx_q <- flag[which.max(cook[flag])]
cig_red <- cig[-idx_q, ]

m_all_red <- lm(CO ~ tar + nico + weight, data = cig_red)
summary(m_all_red)

# Jämför koefficienter, p-värden, R^2
coef_comparison <- cbind(
  full = coef(summary(m_all))[, c("Estimate", "Pr(>|t|)")],
  reduced = coef(summary(m_all_red))[, c("Estimate", "Pr(>|t|)")]
)
coef_comparison

c(R2_full = summary(m_all)$r.squared,
  AdjR2_full = summary(m_all)$adj.r.squared,
  R2_reduced = summary(m_all_red)$r.squared,
  AdjR2_reduced = summary(m_all_red)$adj.r.squared)
```

**Tolkning 2(e):**

* **Tvivelaktig observation:** *BullDurham* (nr 3) – hög Cook’s D (\~2.09) och hög hävstång (\~0.51) ⇒ starkt inflytelserik.
* **Efter att ta bort den:**

  * Endast **tjära** är fortsatt **signifikant** (β≈0.89, p≈2e-4).
  * **Nikotin** blir positiv men **icke-signifikant**; **vikt** fortsatt icke-signifikant.
  * Modellens passform **förbättras**: $R^2$ från 0.919 → **0.935**, justerat $R^2$ från 0.907 → **0.925**, och residual-SE minskar (≈1.45 → **1.16**).

**Hur presentera:** Redovisa resultaten **med och utan** outlier. Slutsatsen är robust: CO förklaras främst av **tjära**; outlieren påverkade koefficienterna (framför allt tecknet för nikotin) och försämrade passformen.

## (f) Modellval för prediktion (justerat $R^2$ och LOOCV-RMSEP)

Vi jämför kandidater med justerat $R^2$ och LOOCV-RMSEP. Vi överväger:

* tar; nico; weight (enskilda prediktorer)
* tar+nico; tar+weight; nico+weight
* tar+nico+weight (full)

Du kan beräkna med eller utan den tvivelaktiga observationen; motivera ditt val. Nedan visar vi båda och väljer modellen med **lägst RMSEP** (vid lika RMSEP bryter vi med högre justerat $R^2$ och parsimoni).

```{r}
# Hjälpare: LOOCV-RMSEP för en linjär modell specificerad med formel och data.frame
loocv_rmsep <- function(formula, data) {
  n <- nrow(data)
  # analytisk LOOCV med hatt-matris (gäller linjär minsta-kvadrat)
  X <- model.matrix(formula, data = data)
  y <- model.response(model.frame(formula, data = data))
  hat <- X %*% solve(t(X) %*% X) %*% t(X)
  fit <- X %*% solve(t(X) %*% X, t(X) %*% y)
  e <- y - fit
  loo_resid <- e / (1 - diag(hat))
  sqrt(mean(loo_resid^2))
}

cands <- list(
  `tar`                = CO ~ tar,
  `nico`               = CO ~ nico,
  `weight`             = CO ~ weight,
  `tar+nico`           = CO ~ tar + nico,
  `tar+weight`         = CO ~ tar + weight,
  `nico+weight`        = CO ~ nico + weight,
  `tar+nico+weight`    = CO ~ tar + nico + weight
)

eval_models <- function(dat) {
  do.call(rbind, lapply(names(cands), function(nm) {
    fm <- cands[[nm]]
    fit <- lm(fm, data = dat)
    data.frame(
      model = nm,
      adj_R2 = summary(fit)$adj.r.squared,
      RMSEP_LOOCV = loocv_rmsep(fm, dat),
      df = length(coef(fit))
    )
  }))
}

tab_full   <- eval_models(cig)
tab_reduced<- eval_models(cig_red)  # utan den flaggade observationen identifierad i (e)

tab_full[order(tab_full$RMSEP_LOOCV), ]
tab_reduced[order(tab_reduced$RMSEP_LOOCV), ]
```

**Tolkning 2(f) – modellval:**

* **Bästa prediktor:** *Tjära*. Den ger lägst LOOCV-RMSEP och högst/lika högt justerat $R^2$ både med och utan den tvivelaktiga observationen.
* **Övriga:** *Nikotin* förklarar CO väl ensam men tillför nästan inget utöver tjära (kollinearitet). *Vikt* är svag.
* **Rekommenderad modell för prediktion:** **CO \~ tar** (enkel modell). Utan outlieren förbättras RMSEP ytterligare (≈1.16 vs ≈1.70) och adj.$R^2$ ökar (≈0.93). Modellen är bäst, enklast och mest stabil.


Vi tar bort outliern för att skapa ett bättre modell för prediktion av CO. 




